{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom sklearn.impute import SimpleImputer \nfrom sklearn.model_selection import train_test_split, GridSearchCV,cross_val_score, cross_val_predict\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report\nfrom sklearn.pipeline import Pipeline\n%matplotlib inline\n\nfrom sklearn.datasets import fetch_lfw_people\nlfw_people = fetch_lfw_people(min_faces_per_person=70, resize=0.5)\n\nxdata = (lfw_people.images)\ny = lfw_people.target\nplt.imshow(np.array(xdata[200,:]).reshape(lfw_people.images.shape[1],lfw_people.images.shape[2]),cmap='gray')\n\nxtrain, xtest, ytrain,ytest = train_test_split(xdata,y,test_size=0.3)\nxtrain = xtrain/255 #obligar a flotante normalizado 0 a 1\nxtest = xtest/255 \nprint(xtrain.shape, xtest.shape)\ntype(xtrain)\nprint('Numero de clases:',len(np.unique(ytrain)))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"l1=0.00001\nl2=0.000001\ntf.keras.backend.clear_session()\ninputA = tf.keras.layers.Input(shape=(xtrain.shape[1],xtrain.shape[2]), name='entradaA')\nflattenA = tf.keras.layers.Flatten(input_shape=(xtrain.shape[1],xtrain.shape[2]))(inputA)\nh1A = tf.keras.layers.Dense(70,activation='relu',name='h1A',kernel_regularizer=tf.keras.regularizers.l1_l2(l1=l1,l2=l2))(flattenA)\noutputA = tf.keras.layers.Dense(10,activation=\"softmax\",name='persona')(h1A)\nmodel_fun = tf.keras.Model(inputs=inputA,outputs=outputA)\ntf.keras.utils.plot_model(model_fun)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_fun.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy()\n                  ,loss_weights = 0.5\n                  ,optimizer=tf.keras.optimizers.Adam(learning_rate=0.005)\n                  ,metrics=[\"accuracy\"])\nhistory = model_fun.fit(x =xtrain, y=ytrain, \n                        epochs=40,batch_size=64,\n                        validation_split=0.3)\n                       ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\nhpd = pd.DataFrame(history.history)\nhpd.plot()\nplt.grid(True)\nplt.ylim(0,2)\nplt.show()\nhpd[['loss','val_loss']].plot()\nplt.grid(True)\nplt.ylim(0,2)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W1 = abs(model_fun.get_layer('h1A').get_weights()[0]).sum(axis=1).reshape(xtest.shape[1],xtest.shape[2])\nWc = np.c_[W1]\nWc /=np.max(Wc)\nplt.imshow(Wc,vmin=0,vmax=1)\nplt.colorbar()\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#matriz de confusion\nfrom sklearn.metrics import confusion_matrix, accuracy_score,classification_report\nfrom sklearn.utils.multiclass import unique_labels\ndef plot_confusion_matrix(y_true, y_pred, classes,\n                          normalize=True,\n                          title=None,\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if not title:\n        if normalize:\n            title = 'Normalized confusion matrix'\n        else:\n            title = 'Confusion matrix, without normalization'\n\n    # Compute confusion matrix\n    cm = confusion_matrix(y_true, y_pred)\n    # Only use the labels that appear in the data\n    #classes = classes[unique_labels(y_true, y_pred)]\n    if normalize:\n        cm = 100*cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    \n    \n    fig, ax = plt.subplots()\n    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n    ax.figure.colorbar(im, ax=ax)\n    # We want to show all ticks...\n    ax.set(xticks=np.arange(cm.shape[1]),\n           yticks=np.arange(cm.shape[0]),\n           # ... and label them with the respective list entries\n           xticklabels=classes, yticklabels=classes,\n           title=title,\n           ylabel='True label',\n           xlabel='Predicted label')\n\n    # Rotate the tick labels and set their alignment.\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n             rotation_mode=\"anchor\")\n\n    # Loop over data dimensions and create text annotations.\n    fmt = '.1f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i in range(cm.shape[0]):\n        for j in range(cm.shape[1]):\n            ax.text(j, i, format(cm[i, j], fmt),\n                    ha=\"center\", va=\"center\",\n                    color=\"white\" if cm[i, j] > thresh else \"black\")\n    fig.tight_layout()\n    return ax\n\nytest_e = model_fun.predict(xtest)\nprint(ytest_e.shape)\nplot_confusion_matrix(ytest, ytest_e.argmax(axis=1),classes=np.unique(lfw_people.target_names))\nplt.title('Multiclase')\nprint(classification_report(ytest, ytest_e.argmax(axis=1)))\n\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"ii = 25\npe= model_fun.predict([xtest[ii][np.newaxis,:,:]])\nprint(pe.argmax(),)\nplt.imshow(np.c_[xtest[ii]], cmap='gray',vmin=0,vmax=1)\nplt.show()\n\nprint(lfw_people.target_names[pe.argmax()])\n\nii = 60\npe= model_fun.predict([xtest[ii][np.newaxis,:,:]])\nprint(pe.argmax(),)\nplt.imshow(np.c_[xtest[ii]], cmap='gray',vmin=0,vmax=1)\nplt.show()\n\nprint(lfw_people.target_names[pe.argmax()])","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}